# nicsiGPT:BillVerifier

##  System Workflow


```text
Start
  â†“
Document Intake
  â†“
Pre-Verification & Alerts (Vendor Portal)
  â†“
Data Extraction (RabbitMQ + LLM + MinIO)
  â†“
Cross-Verification (ERP & PO Matching)
  â†“
Objection & Penalty Analysis (Anomalies, SLA, Contracts)
  â†“
Approval Workflow
    â”œâ”€â”€> No Issues â†’ Human Check â†’ Auto-Approve â†’ Payment Processing
    â””â”€â”€> Issues Found â†’ Dashboard Review â†’ Manual Resolution
  â†“
Integration with ERP/Accounting Systems (APIs)
  â†“
Continuous Learning (User Feedback â†’ AI Model Retraining)
  â†“
End
```


The platform operates on a sophisticated, event-driven workflow designed for scalability and reliability.


**1. Document Intake:**
-   Invoices and supporting documents are received through various channels, with the primary channel being a secure, on-premises **Vendor Portal**.

**2. Pre-Verification & Alerts (Vendor Portal):**
-   If submitted via the portal, a real-time validation engine performs a "pre-flight check." It alerts the vendor of any immediate errors (missing documents, signature issues), preventing incorrect submissions from entering the system.

**3. Data Extraction (Asynchronous Processing):**
-   Upon successful submission, a job message is sent to a **RabbitMQ** processing queue.
-   A Python-based worker service picks up the job, retrieves the documents from **MinIO** object storage, and feeds them into the AI engine.
-   The LLM model performs integrated OCR and data structuring, outputting clean JSON.

**4. Cross-Verification:**
-   The system matches the extracted data against POs and other records fetched from the primary business database (ERP). Discrepancies are flagged.

**5. Objection & Penalty Analysis:**
-   The AI analyzes the invoice against all historical data in the **PostgreSQL** database to flag statistical anomalies and suspicious patterns.
-   It then checks for any applicable penalties or SLA violations based on stored contract terms.

**6. Approval Workflow:**
-   **Straight-Through Processing:** If zero discrepancies or objections are found, the invoice is automatically flagged as "Approved" and sent for payment processing.
-   **Exception Handling:** If any issues are flagged, the invoice and its detailed verification report are routed to the appropriate personnel via a user-facing dashboard for manual review and resolution.

**7. Integration with Core Systems:**
-   The entire system is designed with APIs to integrate seamlessly with existing **Enterprise Resource Planning (ERP)** and accounting systems for data synchronization and financial record-keeping.

**8. Continuous Learning:**
-   The system architecture includes feedback loops where user actions (e.g., overriding a flag, rejecting an invoice) are logged. This data is used to periodically re-train and improve the accuracy of the AI models and the effectiveness of the objection and fraud detection capabilities.

---


##  Scope of the Project

This project automates the verification process through five core modules of intelligence:

### 1.  Invoice & Supporting Document Extraction
The foundation of the platform. The system ingests and understands a wide array of document types submitted as a single package.
-   **Parses:** Invoices, Manpower Reports (MPR), Attendance Reports, Salary Proofs, Completion Certificates, and more.
-   **Technology:** An LLM model with integrated OCR capabilities for high-accuracy, context-aware data extraction.

### ðŸ” Enhanced Document Ingestion Workflow (with Pre-Submission Alerts)

```text
Start
â†“
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phase 1: Staging Area â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â†“
Vendor Enters PO Number
â†“
â†’ Server fetches PO requirements (e.g., required documents, vendor details).
â†“
Vendor Drag-and-Drops PDFs (Invoice, MPR, Salary proofs).
â†“
â†’ Client-side validation: only PDF allowed.
â”œâ”€â”€> If not PDF â†’ show error â†’ reject file.
â””â”€â”€> If PDF â†’ upload to staging endpoint.
â†“
Show "Analyzing..." spinner in UI for each file.
â†“
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phase 2: High-Speed Pre-Flight Check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â†“
â†’ Server triggers a Hybrid Pre-Flight Pipeline in Parallel.
â†“
Parallel Real-Time Checks:
â€¢ Document Existence Check (Business Logic): Compares uploaded files against the PO's required document list.
â€¢ Signature Detection (Dedicated CV Model): A fast CV model checks for a signature on specific documents like certificates.
â€¢ Key Field Extraction (Lightweight LLM Call): For the invoice, the first page is sent to a fast, low-latency LLM (e.g., Gemini Flash) with a highly targeted prompt: "Extract vendor_gstin, invoice_total_amount, and vendor_name. Respond ONLY with JSON."
â€¢ Basic Consistency Check (Database Query): The extracted vendor_gstin is cross-referenced with the vendor's data in the database.
â†“
â†’ Server consolidates results from all parallel checks and sends back a single JSON response with warnings/errors.
â†“
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phase 3: Interactive Feedback Loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â†“
UI renders the real-time result checklist:
â€¢ âœ… Invoice Found
â€¢ âš  GST Mismatch: (Result from LLM + DB Check)
â€¢ âŒ Missing Completion Certificate: (Result from Business Logic Check)
â€¢ âœ… MPR Found
â€¢ âŒ Signature Not Detected: (Result from CV Model Check)
â†“
"Submit" button remains DISABLED until all critical (âŒ) errors are resolved.
â†“
Vendor Corrects Issues:
â†’ Uploads missing/corrected files.
â†’ System re-runs the specific check for the updated file.
â†’ UI updates checklist in real-time.
â†“
â†’ Loop continues until all checks are âœ….
â†“
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phase 4: Final Submission â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â†“
"Submit" Button is ENABLED.
â†“
Vendor clicks "Submit".
â†“
â†’ Server performs Final Validation:
â€¢ Valid PDF Magic Number?
â€¢ PO Number Present?
â”œâ”€â”€> If any invalid â†’ reject & delete â†’ return error.
â””â”€â”€> If all valid â†’ continue.
â†“
Generate submission_id (e.g., sub_a1b2c3d4).
â†“
Move files to permanent storage (e.g., MinIO).
â†“
Generate Final JSON Job Message with metadata + file paths.
â†“
Publish message to RabbitMQ queue.
â†“
â†’ Server returns "Success" response to UI.
â†“
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phase 5: Deep Analysis with LLM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â†“
Worker picks message from RabbitMQ queue.
â†“
â†’ Downloads files from MinIO.
â†“
Convert PDF pages to high-resolution images.
â†“
Image Preprocessing:
â€¢ Deskew
â€¢ Binarize
â€¢ Noise Reduction
â†“
Dynamic Prompt Engineering:
â†’ System constructs a detailed prompt defining the required JSON schema for all documents (invoices, line items, MPR tables, etc.).
â†“
Multimodal LLM Execution:
â†’ The images and detailed prompt are sent to a powerful multimodal LLM (e.g., Gemini Pro) to perform comprehensive, context-aware data extraction.
â†“
Response Validation & Sanitization:
â†’ The LLM's JSON response is parsed and validated against the requested schema.
â†’ Values are sanitized (e.g., text to numbers, date standardization).
â†“
Aggregate structured data for the entire submission into a final, clean JSON object.
â†“
End
```
### 2.  Cross-Verification Engine
The first layer of validation. The engine acts as a diligent auditor, comparing the extracted data against internal business records and ensuring consistency across the submitted documents.
-   Match bills with **Purchase Orders (PO)** to check for budget and line-item discrepancies.
-   Verify attendance data against **manpower deployed** as per the PO.
-   Validate **bank statements/salary payments** against claimed labor costs.
-   Confirm **milestone/completion certificates** are present and match the invoiced claims.

  ### ðŸ” Cross Verification Workflow

This flow ensures all invoices are valid, justified, and aligned with the Purchase Order, attendance, payments, and milestone documentation.

```text
Start
  â†“
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. Match Invoice with PO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â†“
Fetch extracted_data (PostgreSQL) & po_data (ERP)
  â†“
Define Tolerance for Total Amount (e.g., 0.5%)
  â†“
Compare Invoice Total vs PO Total (with tolerance)
  â”œâ”€â”€> If Exceeds â†’ FAIL: "Invoice total exceeds PO"
  â””â”€â”€> If Within Limit â†’ PASS
  â†“
Loop Through Invoice Line Items
  â†“
â†’ For Each Item:
   â”œâ”€â”€ Find Matching PO Line Item (using fuzzy match)
   â”œâ”€â”€ Compare rate and quantity
   â””â”€â”€ Append Result: PASS / FAIL (with reason)
  â†“
Compile Results into JSON Step Report
  â†“
â”€â”€â”€â”€â”€â”€â”€â”€ 2. Verify Attendance vs PO Manpower â”€â”€â”€â”€â”€â”€â”€â”€
  â†“
Fetch extracted_data['attendance_reports'] & po_data
  â†“
Aggregate Total Employees from Attendance Reports
  â†“
Compare total_employees vs PO required_manpower_count
  â”œâ”€â”€> If Overstaffed â†’ FAIL: "Manpower exceeds PO"
  â””â”€â”€> Else â†’ PASS
  â†“
Compile Attendance Check Report
  â†“
â”€â”€â”€â”€â”€â”€â”€ 3. Validate Salary Payments vs Billing â”€â”€â”€â”€â”€â”€â”€
  â†“
Fetch billed_employees from MPR/invoice
  â†“
Fetch paid_employees from salary proofs (bank data)
  â†“
Find Discrepancies: billed - paid â†’ unpaid_employees
  â†“
If unpaid_employees exists:
  â”œâ”€â”€> FAIL: List of names without salary proof
  â””â”€â”€> Else â†’ PASS
  â†“
Compile Salary Validation Report
  â†“
â”€â”€â”€â”€â”€â”€ 4. Confirm Completion Certificates (Milestones) â”€â”€â”€â”€â”€â”€
  â†“
Fetch extracted_data & invoice line items
  â†“
Scan Descriptions for Keywords (milestone, phase, delivery)
  â†“
If Keywords Detected:
  â”œâ”€â”€> Check if Certificate Exists
        â”œâ”€â”€ If Missing â†’ FAIL: "No certificate provided"
        â””â”€â”€ If Present â†’ Compare Certificate & Line Item Description
            â”œâ”€â”€ If Match â†’ PASS
            â””â”€â”€ If Mismatch â†’ FAIL: "Milestone does not match certificate"
  â†“
Compile Milestone Check Report
  â†“
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Final Output â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â†’ Aggregate All Step Reports
â†’ Output Final Cross Verification JSON
â†’ Continue to Next Phase (Objection Analysis)
  â†“
End
```

### 3.  Objection-Aware Validation
The second layer of validation. This module acts as an experienced risk analyst, flagging submissions that, while technically correct, are suspicious based on historical patterns.
-   Flag objections based on a vendor's **historical data**, identifying chronic issues, anomalous billing behavior, and high-risk attributes.

  ### ðŸš¨ Objection-Aware Validation Workflow

This process runs periodically via a cron-triggered script (`objection_engine.py`) and performs deep analysis on already-verified submissions using historical and statistical patterns.

```text
Start
  â†“
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. Fetch Submissions for Objection Analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â†“
Connect to PostgreSQL
  â†“
Query:
SELECT submission_id, vendor_id, verification_report, extracted_data
FROM submissions
WHERE status = 'Pending Review'
AND verification_report->>'objections_processed' IS NULL;
  â†“
Loop Through Each Pending Submission
  â†“
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. Historical Analysis (Per Submission) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â†“
Load: submission_id, vendor_id, extracted_data, verification_report
  â†“
â–¶ï¸ Sub-Step A: Chronic Failure Analysis
  â†“
For each FAIL in verification_report:
  â”œâ”€â”€ Query past similar failures for the same vendor
  â”œâ”€â”€ If failure count > threshold:
  â””â”€â”€ Create objection: { type: "Chronic Violation", detail: ... }

â–¶ï¸ Sub-Step B: Statistical Anomaly Analysis
  â†“
Fetch all historical invoice totals for vendor_id
  â†“
Convert to pandas Series â†’ Calculate Mean & Std Dev
  â†“
If current total > 3Ã—std_dev from mean:
  â””â”€â”€ Create objection: { type: "Anomalous Behavior", detail: ... }

â–¶ï¸ Sub-Step C: High-Risk Attribute Check
  â†“
Look for risky attributes (e.g., 'Miscellaneous Fees') in line items
  â†“
Fetch historical rejection rate for that attribute
  â†“
If risk is high:
  â””â”€â”€ Create objection: { type: "High-Risk Attribute", detail: ... }

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. Merge & Save Objection Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â†“
Compile objections:
objections_found = [
  { "type": "...", "detail": "..." },
  ...
]
  â†“
Prepare JSON Merge Payload:
{
  "objections": objections_found,
  "objections_processed": true
}
  â†“
PostgreSQL Query:
UPDATE submissions
SET verification_report = verification_report || %s::jsonb
WHERE submission_id = %s;
  â†“
Commit the changes
  â†“
Repeat for next submission
  â†“
End
```

### 4.  Vendor Pre-Submission Alerts
A proactive module designed to improve first-time submission quality by preventing errors before they happen.
-   Provides a real-time, interactive feedback loop on the vendor portal.
-   Notifies vendors of **missing documents, data inconsistencies, signature errors, or GST number mismatches** *before* they are allowed to finalize their submission.

### 5.   Penalty & SLA Compliance
The final layer of financial control. The engine automatically calculates and applies contractual financial penalties.
-   Detect contract penalties for **delays, manpower shortfalls, and quality issues**.
-   Calculate penalties as per **RFP, Work Order, or SLA clauses**.
-   Automatically detect and apply any **penalty waivers** to adjust final deductions.

```text
Start
  â†“
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. Trigger & Data Fetch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â†“
Trigger: Submission status = "Pending Review" OR "System Verified"
  â†“
Load from PostgreSQL:
  â”œâ”€â”€ submission_record (includes extracted_data & verification_report)
  â”œâ”€â”€ po_data (from ERP)
  â””â”€â”€ sla_clauses (from ERP)
  â†“
Extract: submission_id, po_number

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. Initialize Financial Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â†“
total_deductions = 0
deductions_detail = []

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. Run Penalty Checks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â†“
â–¶ï¸ Sub-Step A: Delay Penalty Check
  â†“
If milestone FAIL exists in verification_report:
  â”œâ”€â”€ Get completion_date (from extracted_data)
  â”œâ”€â”€ Get milestone_due_date (from po_data)
  â”œâ”€â”€ Get penalty_rate & grace_period (from sla_clauses)
  â””â”€â”€ Calculate:
        penalty_days = (completion_date - due_date) - grace_period
        If penalty_days > 0:
          â”œâ”€â”€ penalty_amount = milestone_value Ã— penalty_rate Ã— penalty_days
          â””â”€â”€ Append to deductions_detail:
              { type: "Late Delivery", amount: ..., reason: ... }
          Update total_deductions

  â†“
â–¶ï¸ Sub-Step B: Manpower Shortfall Penalty
  â†“
If manpower FAIL exists in verification_report:
  â”œâ”€â”€ Get actual_manpower (from attendance)
  â”œâ”€â”€ Get authorized_manpower (from po_data)
  â”œâ”€â”€ Get per_person_penalty (from sla_clauses)
  â””â”€â”€ Calculate:
        shortfall = authorized - actual
        penalty_amount = shortfall Ã— per_person_penalty
        Append to deductions_detail:
          { type: "Manpower Shortfall", amount: ..., reason: ... }
        Update total_deductions

  â†“
â–¶ï¸ Sub-Step C: Quality Issue Penalty
  â†“
Query Quality DB for complaints by po_number
  â†“
If complaint found:
  â”œâ”€â”€ Get penalty_percentage (from sla_clauses)
  â”œâ”€â”€ Get invoice_amount (from extracted_data)
  â””â”€â”€ Calculate:
        penalty_amount = invoice_amount Ã— penalty_percentage
        Append to deductions_detail:
          { type: "Quality Issue", amount: ..., reason: ... }
        Update total_deductions

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. Apply Penalty Waivers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â†“
For each item in deductions_detail:
  â”œâ”€â”€ Check if waiver exists in sla_clauses["penalty_waivers"]
  â””â”€â”€ If found:
        â”œâ”€â”€ Adjust penalty amount (e.g., reduce to 0)
        â””â”€â”€ Update reason field with waiver note
        Recalculate total_deductions

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. Finalize & Save â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â†“
Prepare financial_summary JSON:
{
  "deductions": [...],
  "total_deductions": ...
}
  â†“
PostgreSQL Query:
UPDATE submissions
SET verification_report = jsonb_set(verification_report, '{financial_summary}', %s::jsonb)
WHERE submission_id = %s;
  â†“
Commit changes
  â†“
End
```


### 6.  Compliance Document Validation
Ensures all foundational legal and compliance documents are in order.
-   Validate the integrity and validity of **Bank Guarantees** and **Work Orders**.
-   Check for **bill validity** and detect potential **duplicate submissions** across the system.

```text
  Start
  â†“
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. Trigger & Purpose â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â†“
Trigger:
Part of Cross-Verification Engine â€” runs BEFORE penalties
  â†“
Purpose:
Catch CRITICAL failures in compliance documents (not financial issues)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. Execute Duplicate Submission Check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â†“
Extract:
  â”œâ”€â”€ vendor_id
  â”œâ”€â”€ extracted_invoice_number
  â””â”€â”€ extracted_total_amount
  â†“
PostgreSQL Query:
SELECT submission_id FROM submissions
WHERE vendor_id = %s
AND extracted_data->'invoice'->>'invoice_number' = %s
AND extracted_data->'invoice'->>'total_amount' = %s;
  â†“
If rows returned:
  â””â”€â”€ CRITICAL FAILURE:
      Set status = "Requires Manual Investigation"
      Reason = "Potential Duplicate of submission_id #XYZ"
      â†“
      STOP processing for this submission

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. Execute Bill Validity Check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â†“
Extract:
  â””â”€â”€ invoice_date (from extracted_data)
  â†“
Calculate:
  days_old = (today - invoice_date).days
  â†“
Compare with max_invoice_age (e.g., 90 days)
  â†“
If days_old > max_invoice_age:
  â””â”€â”€ FAIL with reason: "Invoice is time-barred"

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. Execute Work Order / Bank Guarantee Check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â†“
Check if work_order or bank_guarantee object exists in extracted_data
  â†“
If exists:
  â”œâ”€â”€ Extract expiry_date from document
  â”œâ”€â”€ If expiry_date < today â†’ FAIL with reason: "Bank Guarantee expired"
  â†“
  â”œâ”€â”€ Extract order_value or guarantee_amount
  â”œâ”€â”€ Compare with required value in po_data
  â””â”€â”€ If mismatch â†’ FAIL with reason: "Mismatch in Guarantee/Order Value"

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. Update Verification Report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â†“
For each check:
  â””â”€â”€ Append result (PASS / FAIL + reason) to verification_report["standard_checks"]
  â†“
If any check FAILED:
  â””â”€â”€ Set submission status = "Pending Review"

â†“
End
```
---

## ðŸ“Š Data Requirements & Prerequisites

### 1. AI Model Training Data
This data is required **one-time** for the initial training and subsequent periodic re-training of the platform's custom Deep Learning models.

-   **Requirement:** A representative, historical sample for each *custom* document type that the system needs to process.
-   **Specification:** A minimum of **50-100 examples** for each document category. The dataset must be diverse, including documents from various vendors and of varying scan quality (both digital-native and scanned).
-   **Document Types:**
    -   [ ] Vendor Master Record
    -   [ ] Manpower Reports (MPRs)
    -   [ ] Completion Certificates
    -   [ ] Bank Guarantees
    -   [ ] Work Orders
    -   [ ] Salary Proofs / Bank Statements (Anonymized where necessary to protect PII)


---

### 2. Live Transactional Data (For Real-Time Verification)
This data is required for the day-to-day operation of the **Cross-Verification Engine**. The system needs real-time access to query this data.

-   **Requirement:** Access to the **Vendor Master** and **Purchase Order (PO)** data from the primary ERP or business management system.
-   **Specification:** An API endpoint or a read-only database user capable of fetching the following data structure when queried by a `po_number`:

    -   **Vendor Master Record:**
        -   `vendor_id`
        -   `vendor_name`
        -   `vendor_address`
        -   `vendor_gst_number`
        -   `vendor_bank_account_details`
    -   **Purchase Order Header:**
        -   `po_number`
        -   `po_total_value` (Total budget)
        -   `po_status` ('Approved', 'Closed', etc.)
        -   `milestone_due_date`
        -   `required_manpower_count`
        -   `po_category` ('Capital Project', 'Operational Expense', etc.)
    -   **Purchase Order Line Items:**
        -   An array of `approved_line_items`, each containing:
            -   `item_code` (if applicable)
            -   `description`
            -   `quantity_approved`
            -   `rate_approved`

---

### 3. Contractual & Compliance Data
This data is required for the **Penalty & SLA Compliance Engine** to automatically enforce contractual terms.

-   **Requirement:** Access to structured data defining the rules of the contract.
-   **Specification:** For a given PO or Contract ID, the system must be able to retrieve:
    -   **SLA Penalty Clauses:** A structured list of penalty rules (e.g., JSON object) containing:
        -   Rules for `late_delivery_penalty` (type, value, grace period).
        -   Rules for `manpower_shortfall_penalty` (type, value).
        -   Rules for `quality_issue_penalty` (type, value).
    -   **Penalty Waivers:** A list of any pre-approved, active waivers, including the type of penalty waived and the amount/duration.
    -   **Business Rules:** Key operational rules, such as `max_invoice_age_for_submission` (e.g., 90 days).

---

### 4. Ancillary Operational Data
This data is required for specific, advanced validation checks.

-   **Requirement:** Access to any internal systems that log service quality or operational issues.
-   **Specification:** Read-only access to the **Internal Quality Issues Log**. The system needs to be able to query this log by `po_number` to check for any open complaints or documented service failures that may trigger a quality-related penalty.

---

##  Technology Stack

This project is built with a focus on on-premises deployment, security, and scalability.

-   **Backend:** Python (FastAPI)
-   **AI/ML:** Llama3, OpenCV, Tesseract
-   **Database:** PostgreSQL (with JSONB support)
-   **Message Queue:** RabbitMQ
-   **File Storage:** MinIO (S3-Compatible Object Storage)
-   **Frontend Dashboard:** Streamlit
-   **Deployment:** Docker, Cron (for scheduled tasks)

---
